{
  "version": 3,
  "sources": ["../src/core/linear-regression.ts", "../src/core/simple-linear-regression.ts", "../src/core/utils.ts", "../src/index.ts"],
  "sourcesContent": ["import { ILinearRegressionOptions } from '../interfaces';\n\n/**\n * Linear Regression\n *\n * Mean Squared Error (MSE): Error function = Loss function\n * E = (1/n) * sum_from_0_to_n((actual_value - predicted_value)^2)\n * E = (1/n) * sum_from_0_to_n((actual_value - (mx + b))^2)\n * ---------------------------------------------------------\n * Goal: Minimize the error function - find (m, b) with the lowest possible E.\n * How:\n *\n * - Take partial derivative with respect m and also with respect b.\n *   This helps to find the \"m\" that maximally increase E,\n *   and \"b\" that maximally increase E (the steepest ascent).\n *\n * - After we found them, we get the opposite direction\n *   to find the way to decrease E (the steepest descent).\n * ---------------------------------------------------------\n *\n * How to calculate partial derivative of \"m\"?\n * dE/dm = (1/n) * sum_from_0_to_n(2 * (actual_value - (mx + b)) * (-x))\n * dE/dm = (-2/n) * sum_from_0_to_n(x * (actual_value - (mx + b)))\n * ---------------------------------------------------------\n *\n * How to calculate partial derivative of \"b\"?\n * dE/db = (-2/n) * sum_from_0_to_n(actual_value - (mx + b))\n * ---------------------------------------------------------\n *\n * After the derivatives are found (the steepest ascent)\n * we need to find the steepest descent:\n *\n * new_m = current_m - learning_rate * dE/dm\n * new_b = current_b - learning_rate * dE/db\n *\n * General Form:\n * ------------\n * y = w1*x1 + w2*x2 + \u2026 + wn*xn + b\n * [w1, ..., wn] = weights, b = bias\n */\nexport class LinearRegression {\n\n    options: ILinearRegressionOptions;\n    weights: number[];\n    bias: number;\n\n    features: number[][];\n    labels: number[];\n    featuresSize: number;\n\n    batchSize: number;\n\n    constructor(options: ILinearRegressionOptions) {\n        this.options = options;\n\n        this.features = JSON.parse(JSON.stringify(this.options.features));\n        this.labels = JSON.parse(JSON.stringify(this.options.labels));\n        this.featuresSize = this.features.length > 0 ? this.features[0].length : 0;\n\n        if(!this.validateInput()) {\n            throw new Error('The input is not valid. Number of features should match the number of labels, and all features should have the same size.');\n        }\n\n        // Initialize weights to zero\n        this.weights = LinearRegression.initZeroArray(this.featuresSize);\n        this.bias = 0;\n\n        this.batchSize = this.options.batchSize ?? this.features.length;\n    }\n\n    private validateInput(): boolean {\n        if(this.features.length <= 0 || this.features.length !== this.labels.length) return false;\n        const _featuresSize = this.features[0].length;\n\n        for(const feature of this.features) {\n            if(feature.length !== _featuresSize) return false;\n        }\n\n        return true;\n    }\n\n    private static initZeroArray(len: number) {\n        const arr: number[] = [];\n        arr.length = len;\n        arr.fill(0);\n        return arr;\n    }\n\n    private shuffle() {\n        const indices: number[] = [];\n        for(let i=0; i<this.featuresSize; i++) {\n            indices.push(i);\n        }\n\n        for (let i = this.features.length - 1; i > 0; i--) {\n            const j = Math.floor(Math.random() * (i + 1));\n            [indices[i], indices[j]] = [indices[j], indices[i]];\n        }\n\n        for (let i = this.features.length - 1; i > 0; i--) {\n            [this.features[i], this.features[indices[i]]] = [this.features[indices[i]], this.features[i]];\n            [this.labels[i], this.labels[indices[i]]] = [this.labels[indices[i]], this.labels[i]];\n        }\n    }\n\n    private gradientDescent(batchFeatures: number[][], batchLabels: number[]) : [ number[], number ] {\n\n        const mGradientSums = LinearRegression.initZeroArray(this.featuresSize);\n        let bGradientSum = 0;\n\n        for (let i = 0; i < batchFeatures.length; i++) {\n\n            const _features: number[] = batchFeatures[i];\n\n            const actualValue = batchLabels[i];\n            const predictedValue = this.predict(_features);\n            const diff = actualValue - predictedValue;\n\n            // dE/dm = (-2/n) * sum_from_0_to_n(x * (actual_value - (mx + b)))\n            for (let j = 0; j < this.featuresSize; j++) {\n                mGradientSums[j] += -2 * _features[j] * diff;\n            }\n\n            // dE/db = (-2/n) * sum_from_0_to_n(actual_value - (mx + b))\n            bGradientSum += -2 * diff;\n        }\n\n        // Update weights and bias using learning rate\n        const newWeights = [];\n\n        for(let i=0; i<this.weights.length; i++) {\n            const _weight = this.weights[i];\n\n            // new_m = current_m - learning_rate * dE/dm\n            const gradientM = _weight - (this.options.learningRate / this.batchSize) * mGradientSums[i];\n            newWeights.push(gradientM);\n        }\n\n        // new_b = current_b - learning_rate * dE/db\n        const newBias = this.bias - (this.options.learningRate / this.batchSize) * bGradientSum;\n\n        return [newWeights, newBias];\n    }\n\n    fit() {\n        const startTime = performance.now();\n\n        for(let i = 0; i < this.options.epochs; i++) {\n\n            if (this.options.shuffle) {\n                this.shuffle();\n            }\n\n            // Split data into mini-batches\n            for (let j = 0; j < this.features.length; j += this.batchSize) {\n\n                const batchFeatures = this.features.slice(j, j + this.batchSize);\n                const batchLabels = this.labels.slice(j, j + this.batchSize);\n\n                const [newWeights, newBias] = this.gradientDescent(batchFeatures, batchLabels);\n\n                if (typeof this.options.epochsCallback === 'function') {\n                    const endTime = performance.now();\n                    this.options.epochsCallback({\n                        epoch: i,\n                        epochsCount: this.options.epochs,\n                        newWeights,\n                        newBias,\n                        time: endTime - startTime,\n                    });\n                }\n\n                this.weights = newWeights;\n                this.bias = newBias;\n            }\n        }\n\n        return [this.weights, this.bias];\n    }\n\n    /**\n     * y = w1*x1 + w2*x2 + \u2026 + wn*xn + b\n     */\n    predict(features: number[], logs?: boolean) : number {\n\n        if (features.length !== this.weights.length) {\n            throw new Error('Number of features does not match the number of weights.');\n        }\n\n        const startTime = performance.now();\n\n        // Calculate the dot product of features and weights and add bias\n        // return this.m * x + this.b;\n        let prediction = this.bias;\n\n        for (let i = 0; i < features.length; i++) {\n            prediction += features[i] * this.weights[i];\n        }\n\n        if(logs) {\n            console.log(`Prediction = ${ prediction }, ${ performance.now() - startTime } ms`);\n        }\n\n        return prediction;\n    }\n\n    predictBatch(featuresBatch: number[][], logs?: boolean) : number[] {\n        const predictions: number[] = [];\n        const startTime = performance.now();\n\n        for(const batch of featuresBatch) {\n            predictions.push(this.predict(batch));\n        }\n\n        if(logs) {\n            console.log(`Predictions = ${ predictions }, ${ performance.now() - startTime } ms`);\n        }\n\n        return predictions;\n    }\n\n    /**\n     * R-squared is the coefficient of determination value,\n     * which measures the goodness of fit of the regression line to the data.\n     * A value close to 1 indicates a perfect fit.\n     * R-Squared range: [0, 1]\n     *\n     * Formula:\n     * --------\n     * R^2 = 1 - (residualSumOfSquares / totalSumOfSquares)\n     * RSS (Residual Sum of Squares) is the sum of squared differences\n     *      between the actual and predicted values\n     * TSS (Total Sum of Squares) is the sum of squared differences between\n     *      the actual values and the mean of the actual values\n     */\n    rSquared() {\n        let residualSumOfSquares = 0; // rss\n        let totalSumOfSquares = 0; // tss\n\n        const meanOfActualValues = this.labels.length <= 0 ? 0 :\n            this.labels.reduce((sum, x) => sum + x) / this.labels.length; // yMean\n\n        for (let i = 0; i < this.features.length; i++) {\n            const actualValue = this.labels[i];\n            const predictedValue = this.predict(this.features[i]);\n\n            residualSumOfSquares += (actualValue - predictedValue) ** 2;\n            totalSumOfSquares += (actualValue - meanOfActualValues) ** 2;\n        }\n\n        return 1 - (residualSumOfSquares / totalSumOfSquares);\n    }\n\n    /**\n     * MSE = (1/n) * sum_from_0_to_n((actual_value - (mx + b))^2)\n     * The ideal value of Mean Squared Error (MSE) is 0.\n     * Achieving an MSE of 0 would mean that the model perfectly predicts the target variable\n     * for every data point in the training set. However, it's important to note\n     * that achieving an MSE of exactly 0 is extremely rare and often unrealistic, especially with real-world data.\n     */\n    meanSquaredError() {\n        if(this.features.length <= 0) return 0;\n\n        let mse = 0;\n\n        for (let i = 0; i < this.features.length; i++) {\n            const actualValue = this.labels[i];\n            const predictedValue = this.predict(this.features[i]);\n\n            mse += (actualValue - predictedValue) ** 2;\n        }\n\n        mse /= this.features.length;\n\n        return mse;\n    }\n\n    /**\n     * Compute the Pearson correlation coefficient.\n     * --------------------------------------------\n     * It is a statistical measure that quantifies the strength and direction of the linear relationship\n     * between two variables. It's commonly used to assess the strength of association\n     * between two continuous variables.\n     *\n     * P = (sum_of(feature - mean(feature_col)) * sum_of(label - mean(label_col))) / sqrt(  sum_of( (feature - mean(feature_col))^2 ) *  sum_of( (y - mean(label_col))^2 ) )\n     *\n     * Range [-1, 1]\n     * r=1 indicates a perfect positive linear relationship,\n     *      meaning that as one variable increases, the other variable increases proportionally.\n     *\n     * r=\u22121 indicates a perfect negative linear relationship, meaning that as one variable increases,\n     *      the other variable decreases proportionally.\n     *\n     * r= 0 indicates no linear relationship between the variables.\n     */\n    pearson = () : number[] => {\n        if (this.features.length <= 0 || this.labels.length <= 0) return [];\n\n        const pearsonCoefficients: number[] = [];\n        const labelsMean = this.labels.reduce((sum, y) => sum + y, 0) / this.labels.length; // yMean\n\n        for (let featureIndex = 0; featureIndex < this.featuresSize; featureIndex++) {\n            let sumXY = 0; // sum_of((feature - featuresColumnMean) * (label - labelsMean));\n            let sumX2 = 0; // sum_of((feature - featuresColumnMean) ** 2)\n            let sumY2 = 0; // sum_of((label - labelsMean) ** 2)\n\n            const featuresColumn = this.features.map(feature => feature[featureIndex]);\n            const featuresColumnMean = featuresColumn.reduce((sum, x) => sum + x, 0) / featuresColumn.length; // xMean\n\n            for (let i = 0; i < this.features.length; i++) {\n                const feature = this.features[i][featureIndex];\n                const label = this.labels[i];\n\n                sumXY += (feature - featuresColumnMean) * (label - labelsMean);\n                sumX2 += (feature - featuresColumnMean) ** 2;\n                sumY2 += (label - labelsMean) ** 2;\n            }\n\n            pearsonCoefficients.push((sumX2 === 0 || sumY2 === 0) ? 0 : (sumXY / Math.sqrt(sumX2 * sumY2)));\n        }\n\n        return pearsonCoefficients;\n    }\n}", "import { LinearRegression } from './linear-regression';\nimport { ISimpleLinearRegressionOptions, ILinearRegressionOptions } from '../interfaces';\n\nexport class SimpleLinearRegression extends LinearRegression{\n\n    constructor(options: ISimpleLinearRegressionOptions) {\n\n        const _features: number[][] = [];\n\n        for(const feature of options.features) {\n            _features.push([feature]);\n        }\n\n        const _options: ILinearRegressionOptions = {\n            ...options,\n            features: _features,\n        };\n\n        super(_options);\n    }\n}", "export interface ISplitDataOptions {\n    features: number[][];\n    labels: number[];\n    testSetSize: number;\n    validationSetSize?: number;\n}\n\nexport interface ISplitDataResult {\n    featuresTrain: number[][];\n    featuresTest: number[][];\n    featuresValidation?: number[][];\n\n    labelsTrain: number[];\n    labelsTest: number[];\n    labelsValidation?: number[];\n}\n\nexport const splitData = (options: ISplitDataOptions) : ISplitDataResult => {\n\n    const n = options.features.length;\n\n    if(n <= 0 || n !== options.labels.length) {\n        throw new Error('Number of features does not match the number of labels.');\n    }\n\n    if(options.testSetSize < 0 || options.testSetSize > 1) {\n        throw new Error('testSetSize should be in the range (0, 1).');\n    }\n\n    if(options.validationSetSize !== undefined) {\n        if(options.validationSetSize < 0 || options.validationSetSize > 1) {\n            throw new Error('validationSetSize should be in the range (0, 1).');\n        }\n\n        if(options.validationSetSize + options.testSetSize > 1) {\n            throw new Error('Sum of testSetSize and validationSetSize should not exceed 1.');\n        }\n    }\n\n    const validationSetSizePercent = options.validationSetSize ?? 0;\n    const testSetSizePercent = options.testSetSize;\n    // const trainingSetSizePercent = 1 - testSetSizePercent - validationSetSizePercent;\n\n    const validationSetSize = Math.round(n * validationSetSizePercent);\n    const testSetSize = Math.round(n * testSetSizePercent);\n    const trainingSetSize = n - validationSetSize - testSetSize;\n\n    // start to end (end not included)\n    const featuresTrain: number[][] = options.features.slice(0, trainingSetSize);\n    const labelsTrain: number[] = options.labels.slice(0, trainingSetSize);\n\n    const secondSplitPoint = trainingSetSize + testSetSize;\n    const featuresTest: number[][] = options.features.slice(trainingSetSize, secondSplitPoint);\n    const labelsTest: number[] = options.labels.slice(trainingSetSize, secondSplitPoint);\n\n    const featuresValidation: number[][] = validationSetSize <= 0 ? [] : options.features.slice(secondSplitPoint);\n    const labelsValidation: number[] = validationSetSize <= 0 ? [] : options.labels.slice(secondSplitPoint);\n\n    return {\n        featuresTrain,\n        featuresTest,\n        featuresValidation,\n        labelsTrain,\n        labelsTest,\n        labelsValidation,\n    }\n};", "import * as LinearRegression from './core/linear-regression';\nimport * as SimpleLinearRegression from './core/simple-linear-regression';\nimport * as utils from './core/utils';\n\nconst api = {\n    ...LinearRegression,\n    ...SimpleLinearRegression,\n    ...utils,\n};\n\ndeclare global {\n    interface Window {\n        mzMl: typeof api,\n    }\n}\n\nwindow.mzMl = window.mzMl || api;\n\nexport * from './core/linear-regression';\nexport * from './core/simple-linear-regression';\nexport * from './core/utils';"],
  "mappings": ";;;;;;gjBAAA,IAAAA,EAAA,GAAAC,EAAAD,EAAA,sBAAAE,IAwCO,IAAMC,EAAN,KAAuB,CAY1B,YAAYC,EAAmC,CAV/CC,EAAA,gBACAA,EAAA,gBACAA,EAAA,aAEAA,EAAA,iBACAA,EAAA,eACAA,EAAA,qBAEAA,EAAA,kBAqPAA,EAAA,eAAU,IAAiB,CACvB,GAAI,KAAK,SAAS,QAAU,GAAK,KAAK,OAAO,QAAU,EAAG,MAAO,CAAC,EAElE,IAAMC,EAAgC,CAAC,EACjCC,EAAa,KAAK,OAAO,OAAO,CAACC,EAAKC,IAAMD,EAAMC,EAAG,CAAC,EAAI,KAAK,OAAO,OAE5E,QAASC,EAAe,EAAGA,EAAe,KAAK,aAAcA,IAAgB,CACzE,IAAIC,EAAQ,EACRC,EAAQ,EACRC,EAAQ,EAENC,EAAiB,KAAK,SAAS,IAAIC,GAAWA,EAAQL,CAAY,CAAC,EACnEM,EAAqBF,EAAe,OAAO,CAACN,EAAKS,IAAMT,EAAMS,EAAG,CAAC,EAAIH,EAAe,OAE1F,QAASI,EAAI,EAAGA,EAAI,KAAK,SAAS,OAAQA,IAAK,CAC3C,IAAMH,EAAU,KAAK,SAASG,CAAC,EAAER,CAAY,EACvCS,EAAQ,KAAK,OAAOD,CAAC,EAE3BP,IAAUI,EAAUC,IAAuBG,EAAQZ,GACnDK,GAAUQ,EAAAL,EAAUC,EAAuB,GAC3CH,GAAUO,EAAAD,EAAQZ,EAAe,EACrC,CAEAD,EAAoB,KAAMM,IAAU,GAAKC,IAAU,EAAK,EAAKF,EAAQ,KAAK,KAAKC,EAAQC,CAAK,CAAE,CAClG,CAEA,OAAOP,CACX,GAlUJ,IAAAe,EA2DQ,GANA,KAAK,QAAUjB,EAEf,KAAK,SAAW,KAAK,MAAM,KAAK,UAAU,KAAK,QAAQ,QAAQ,CAAC,EAChE,KAAK,OAAS,KAAK,MAAM,KAAK,UAAU,KAAK,QAAQ,MAAM,CAAC,EAC5D,KAAK,aAAe,KAAK,SAAS,OAAS,EAAI,KAAK,SAAS,CAAC,EAAE,OAAS,EAEtE,CAAC,KAAK,cAAc,EACnB,MAAM,IAAI,MAAM,2HAA2H,EAI/I,KAAK,QAAUD,EAAiB,cAAc,KAAK,YAAY,EAC/D,KAAK,KAAO,EAEZ,KAAK,WAAYkB,EAAA,KAAK,QAAQ,YAAb,KAAAA,EAA0B,KAAK,SAAS,MAC7D,CAEQ,eAAyB,CAC7B,GAAG,KAAK,SAAS,QAAU,GAAK,KAAK,SAAS,SAAW,KAAK,OAAO,OAAQ,MAAO,GACpF,IAAMC,EAAgB,KAAK,SAAS,CAAC,EAAE,OAEvC,QAAUP,KAAW,KAAK,SACtB,GAAGA,EAAQ,SAAWO,EAAe,MAAO,GAGhD,MAAO,EACX,CAEA,OAAe,cAAcC,EAAa,CACtC,IAAMC,EAAgB,CAAC,EACvB,OAAAA,EAAI,OAASD,EACbC,EAAI,KAAK,CAAC,EACHA,CACX,CAEQ,SAAU,CACd,IAAMC,EAAoB,CAAC,EAC3B,QAAQP,EAAE,EAAGA,EAAE,KAAK,aAAcA,IAC9BO,EAAQ,KAAKP,CAAC,EAGlB,QAASA,EAAI,KAAK,SAAS,OAAS,EAAGA,EAAI,EAAGA,IAAK,CAC/C,IAAMQ,EAAI,KAAK,MAAM,KAAK,OAAO,GAAKR,EAAI,EAAE,EAC5C,CAACO,EAAQP,CAAC,EAAGO,EAAQC,CAAC,CAAC,EAAI,CAACD,EAAQC,CAAC,EAAGD,EAAQP,CAAC,CAAC,CACtD,CAEA,QAASA,EAAI,KAAK,SAAS,OAAS,EAAGA,EAAI,EAAGA,IAC1C,CAAC,KAAK,SAASA,CAAC,EAAG,KAAK,SAASO,EAAQP,CAAC,CAAC,CAAC,EAAI,CAAC,KAAK,SAASO,EAAQP,CAAC,CAAC,EAAG,KAAK,SAASA,CAAC,CAAC,EAC5F,CAAC,KAAK,OAAOA,CAAC,EAAG,KAAK,OAAOO,EAAQP,CAAC,CAAC,CAAC,EAAI,CAAC,KAAK,OAAOO,EAAQP,CAAC,CAAC,EAAG,KAAK,OAAOA,CAAC,CAAC,CAE5F,CAEQ,gBAAgBS,EAA2BC,EAA8C,CAE7F,IAAMC,EAAgB1B,EAAiB,cAAc,KAAK,YAAY,EAClE2B,EAAe,EAEnB,QAASZ,EAAI,EAAGA,EAAIS,EAAc,OAAQT,IAAK,CAE3C,IAAMa,EAAsBJ,EAAcT,CAAC,EAErCc,EAAcJ,EAAYV,CAAC,EAC3Be,EAAiB,KAAK,QAAQF,CAAS,EACvCG,EAAOF,EAAcC,EAG3B,QAASP,EAAI,EAAGA,EAAI,KAAK,aAAcA,IACnCG,EAAcH,CAAC,GAAK,GAAKK,EAAUL,CAAC,EAAIQ,EAI5CJ,GAAgB,GAAKI,CACzB,CAGA,IAAMC,EAAa,CAAC,EAEpB,QAAQjB,EAAE,EAAGA,EAAE,KAAK,QAAQ,OAAQA,IAAK,CAIrC,IAAMkB,EAHU,KAAK,QAAQlB,CAAC,EAGD,KAAK,QAAQ,aAAe,KAAK,UAAaW,EAAcX,CAAC,EAC1FiB,EAAW,KAAKC,CAAS,CAC7B,CAGA,IAAMC,EAAU,KAAK,KAAQ,KAAK,QAAQ,aAAe,KAAK,UAAaP,EAE3E,MAAO,CAACK,EAAYE,CAAO,CAC/B,CAEA,KAAM,CACF,IAAMC,EAAY,YAAY,IAAI,EAElC,QAAQpB,EAAI,EAAGA,EAAI,KAAK,QAAQ,OAAQA,IAAK,CAErC,KAAK,QAAQ,SACb,KAAK,QAAQ,EAIjB,QAASQ,EAAI,EAAGA,EAAI,KAAK,SAAS,OAAQA,GAAK,KAAK,UAAW,CAE3D,IAAMC,EAAgB,KAAK,SAAS,MAAMD,EAAGA,EAAI,KAAK,SAAS,EACzDE,EAAc,KAAK,OAAO,MAAMF,EAAGA,EAAI,KAAK,SAAS,EAErD,CAACS,EAAYE,CAAO,EAAI,KAAK,gBAAgBV,EAAeC,CAAW,EAE7E,GAAI,OAAO,KAAK,QAAQ,gBAAmB,WAAY,CACnD,IAAMW,EAAU,YAAY,IAAI,EAChC,KAAK,QAAQ,eAAe,CACxB,MAAOrB,EACP,YAAa,KAAK,QAAQ,OAC1B,WAAAiB,EACA,QAAAE,EACA,KAAME,EAAUD,CACpB,CAAC,CACL,CAEA,KAAK,QAAUH,EACf,KAAK,KAAOE,CAChB,CACJ,CAEA,MAAO,CAAC,KAAK,QAAS,KAAK,IAAI,CACnC,CAKA,QAAQG,EAAoBC,EAAyB,CAEjD,GAAID,EAAS,SAAW,KAAK,QAAQ,OACjC,MAAM,IAAI,MAAM,0DAA0D,EAG9E,IAAMF,EAAY,YAAY,IAAI,EAI9BI,EAAa,KAAK,KAEtB,QAASxB,EAAI,EAAGA,EAAIsB,EAAS,OAAQtB,IACjCwB,GAAcF,EAAStB,CAAC,EAAI,KAAK,QAAQA,CAAC,EAG9C,OAAGuB,GACC,QAAQ,IAAI,gBAAiBC,MAAiB,YAAY,IAAI,EAAIJ,MAAe,EAG9EI,CACX,CAEA,aAAaC,EAA2BF,EAA2B,CAC/D,IAAMG,EAAwB,CAAC,EACzBN,EAAY,YAAY,IAAI,EAElC,QAAUO,KAASF,EACfC,EAAY,KAAK,KAAK,QAAQC,CAAK,CAAC,EAGxC,OAAGJ,GACC,QAAQ,IAAI,iBAAkBG,MAAkB,YAAY,IAAI,EAAIN,MAAe,EAGhFM,CACX,CAgBA,UAAW,CACP,IAAIE,EAAuB,EACvBC,EAAoB,EAElBC,EAAqB,KAAK,OAAO,QAAU,EAAI,EACjD,KAAK,OAAO,OAAO,CAACxC,EAAKS,IAAMT,EAAMS,CAAC,EAAI,KAAK,OAAO,OAE1D,QAASC,EAAI,EAAGA,EAAI,KAAK,SAAS,OAAQA,IAAK,CAC3C,IAAMc,EAAc,KAAK,OAAOd,CAAC,EAC3Be,EAAiB,KAAK,QAAQ,KAAK,SAASf,CAAC,CAAC,EAEpD4B,GAAyB1B,EAAAY,EAAcC,EAAmB,GAC1Dc,GAAsB3B,EAAAY,EAAcgB,EAAuB,EAC/D,CAEA,MAAO,GAAKF,EAAuBC,CACvC,CASA,kBAAmB,CACf,GAAG,KAAK,SAAS,QAAU,EAAG,MAAO,GAErC,IAAIE,EAAM,EAEV,QAAS/B,EAAI,EAAGA,EAAI,KAAK,SAAS,OAAQA,IAAK,CAC3C,IAAMc,EAAc,KAAK,OAAOd,CAAC,EAC3Be,EAAiB,KAAK,QAAQ,KAAK,SAASf,CAAC,CAAC,EAEpD+B,GAAQ7B,EAAAY,EAAcC,EAAmB,EAC7C,CAEA,OAAAgB,GAAO,KAAK,SAAS,OAEdA,CACX,CAgDJ,ECnUA,IAAAC,EAAA,GAAAC,EAAAD,EAAA,4BAAAE,IAGO,IAAMC,EAAN,cAAqCC,CAAgB,CAExD,YAAYC,EAAyC,CAEjD,IAAMC,EAAwB,CAAC,EAE/B,QAAUC,KAAWF,EAAQ,SACzBC,EAAU,KAAK,CAACC,CAAO,CAAC,EAG5B,IAAMC,EAAqCC,EAAAC,EAAA,GACpCL,GADoC,CAEvC,SAAUC,CACd,GAEA,MAAME,CAAQ,CAClB,CACJ,ECpBA,IAAAG,EAAA,GAAAC,EAAAD,EAAA,eAAAE,IAiBO,IAAMA,EAAaC,GAAkD,CAjB5E,IAAAC,EAmBI,IAAMC,EAAIF,EAAQ,SAAS,OAE3B,GAAGE,GAAK,GAAKA,IAAMF,EAAQ,OAAO,OAC9B,MAAM,IAAI,MAAM,yDAAyD,EAG7E,GAAGA,EAAQ,YAAc,GAAKA,EAAQ,YAAc,EAChD,MAAM,IAAI,MAAM,4CAA4C,EAGhE,GAAGA,EAAQ,oBAAsB,OAAW,CACxC,GAAGA,EAAQ,kBAAoB,GAAKA,EAAQ,kBAAoB,EAC5D,MAAM,IAAI,MAAM,kDAAkD,EAGtE,GAAGA,EAAQ,kBAAoBA,EAAQ,YAAc,EACjD,MAAM,IAAI,MAAM,+DAA+D,CAEvF,CAEA,IAAMG,GAA2BF,EAAAD,EAAQ,oBAAR,KAAAC,EAA6B,EACxDG,EAAqBJ,EAAQ,YAG7BK,EAAoB,KAAK,MAAMH,EAAIC,CAAwB,EAC3DG,EAAc,KAAK,MAAMJ,EAAIE,CAAkB,EAC/CG,EAAkBL,EAAIG,EAAoBC,EAG1CE,EAA4BR,EAAQ,SAAS,MAAM,EAAGO,CAAe,EACrEE,EAAwBT,EAAQ,OAAO,MAAM,EAAGO,CAAe,EAE/DG,EAAmBH,EAAkBD,EACrCK,EAA2BX,EAAQ,SAAS,MAAMO,EAAiBG,CAAgB,EACnFE,EAAuBZ,EAAQ,OAAO,MAAMO,EAAiBG,CAAgB,EAE7EG,EAAiCR,GAAqB,EAAI,CAAC,EAAIL,EAAQ,SAAS,MAAMU,CAAgB,EACtGI,EAA6BT,GAAqB,EAAI,CAAC,EAAIL,EAAQ,OAAO,MAAMU,CAAgB,EAEtG,MAAO,CACH,cAAAF,EACA,aAAAG,EACA,mBAAAE,EACA,YAAAJ,EACA,WAAAG,EACA,iBAAAE,CACJ,CACJ,EC9DA,IAAMC,EAAMC,MAAA,GACLC,GACAC,GACAC,GASP,OAAO,KAAO,OAAO,MAAQJ",
  "names": ["linear_regression_exports", "__export", "LinearRegression", "LinearRegression", "options", "__publicField", "pearsonCoefficients", "labelsMean", "sum", "y", "featureIndex", "sumXY", "sumX2", "sumY2", "featuresColumn", "feature", "featuresColumnMean", "x", "i", "label", "__pow", "_a", "_featuresSize", "len", "arr", "indices", "j", "batchFeatures", "batchLabels", "mGradientSums", "bGradientSum", "_features", "actualValue", "predictedValue", "diff", "newWeights", "gradientM", "newBias", "startTime", "endTime", "features", "logs", "prediction", "featuresBatch", "predictions", "batch", "residualSumOfSquares", "totalSumOfSquares", "meanOfActualValues", "mse", "simple_linear_regression_exports", "__export", "SimpleLinearRegression", "SimpleLinearRegression", "LinearRegression", "options", "_features", "feature", "_options", "__spreadProps", "__spreadValues", "utils_exports", "__export", "splitData", "options", "_a", "n", "validationSetSizePercent", "testSetSizePercent", "validationSetSize", "testSetSize", "trainingSetSize", "featuresTrain", "labelsTrain", "secondSplitPoint", "featuresTest", "labelsTest", "featuresValidation", "labelsValidation", "api", "__spreadValues", "linear_regression_exports", "simple_linear_regression_exports", "utils_exports"]
}
